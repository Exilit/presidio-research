{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Azure Text Analytics for PII detection using the Presidio Evaluator framework\n",
    "\n",
    "Prerequisites: \n",
    " - Azure subscription\n",
    " - Once you have your Azure subscription, create a Language resource in the Azure portal to get your key and endpoint. After it deploys, click Go to resource.\n",
    " - You'll need the key and endpoint from the resource you create to connect your application to the API. You'll paste your key and endpoint into the code below later in the quickstart.\n",
    " - You can use the free pricing tier (Free F0) to try the service, and upgrade later to a paid tier for production.\n",
    " - To use the Analyze feature, you'll need a Language resource with the standard (S) pricing tier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stanza and spacy_stanza are not installed\n",
      "Flair is not installed by default\n",
      "Flair is not installed\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "\n",
    "from presidio_evaluator import InputSample\n",
    "from presidio_evaluator.evaluation import Evaluator, ModelError\n",
    "from presidio_evaluator.models import TextAnalyticsWrapper\n",
    "from presidio_evaluator.experiment_tracking import get_experiment_tracker\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing input:   0%|          | 0/1500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model en_core_web_sm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing input: 100%|██████████| 1500/1500 [00:12<00:00, 119.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"synth_dataset_v2.json\"\n",
    "dataset = InputSample.read_dataset_json(Path(Path.cwd().parent.parent, \"data\", dataset_name))\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_counter = Counter()\n",
    "for sample in dataset:\n",
    "    for tag in sample.tags:\n",
    "        entity_counter[tag] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count per entity:\n",
      "[('O', 19626),\n",
      " ('STREET_ADDRESS', 3071),\n",
      " ('PERSON', 1369),\n",
      " ('GPE', 521),\n",
      " ('ORGANIZATION', 504),\n",
      " ('PHONE_NUMBER', 350),\n",
      " ('DATE_TIME', 219),\n",
      " ('TITLE', 142),\n",
      " ('CREDIT_CARD', 136),\n",
      " ('US_SSN', 80),\n",
      " ('AGE', 74),\n",
      " ('NRP', 55),\n",
      " ('ZIP_CODE', 50),\n",
      " ('EMAIL_ADDRESS', 49),\n",
      " ('DOMAIN_NAME', 37),\n",
      " ('IP_ADDRESS', 22),\n",
      " ('IBAN_CODE', 21),\n",
      " ('US_DRIVER_LICENSE', 9)]\n",
      "\n",
      "Example sentence:\n",
      "Full text: What are my options?\n",
      "Spans: []\n",
      "Tokens: What are my options?\n",
      "Tags: ['O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "Min and max number of tokens in dataset:\n",
      "Min: 3, Max: 78\n",
      "\n",
      "Min and max sentence length in dataset:\n",
      "Min: 9, Max: 407\n"
     ]
    }
   ],
   "source": [
    "print(\"Count per entity:\")\n",
    "pprint(entity_counter.most_common())\n",
    "\n",
    "print(\"\\nExample sentence:\")\n",
    "print(dataset[1])\n",
    "\n",
    "print(\"\\nMin and max number of tokens in dataset:\")\n",
    "print(\n",
    "    f\"Min: {min([len(sample.tokens) for sample in dataset])}, \"\n",
    "    f\"Max: {max([len(sample.tokens) for sample in dataset])}\"\n",
    ")\n",
    "\n",
    "print(\"\\nMin and max sentence length in dataset:\")\n",
    "print(\n",
    "    f\"Min: {min([len(sample.full_text) for sample in dataset])}, \"\n",
    "    f\"Max: {max([len(sample.full_text) for sample in dataset])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Text analytics Analyzer\"\n",
    "# Paste your Azure Text Analytics key and endpoint here\n",
    "key = \"XXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "endpoint = \"https://xxxxxxxxxxx.cognitiveservices.azure.com/\"\n",
    "model = TextAnalyticsWrapper(ta_key=key, ta_endpoint=endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Azure Text Analytics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating <class 'presidio_evaluator.models.text_analytics_wrapper.TextAnalyticsWrapper'>: 100%|██████████| 1/1 [00:00<00:00,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving experiment data to experiment_20221128-094558.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating Azure Text Analytics.\")\n",
    "\n",
    "experiment = get_experiment_tracker()\n",
    "\n",
    "# Mapping from dataset Entities to Text Analytics Entities. \n",
    "# All supported PII entity categories in Text Analytics are listed in this link: https://learn.microsoft.com/en-us/azure/cognitive-services/language-service/personally-identifiable-information/concepts/conversations-entity-categories\n",
    "i2b2_entities_to_text_analytics =  {\"PERSON\":\"Person\",\n",
    "                                \"STREET_ADDRESS\":\"Address\",\n",
    "                                \"GPE\": \"O\",\n",
    "                                \"PHONE_NUMBER\":\"PhoneNumber\",\n",
    "                                \"ORGANIZATION\":\"Organization\",\n",
    "                                \"DATE_TIME\": \"DateTime\",\n",
    "                                \"TITLE\":\"O\",\n",
    "                                \"CREDIT_CARD\":\"CreditCardNumber\",\n",
    "                                \"US_SSN\":\"USSocialSecurityNumber\",\n",
    "                                \"AGE\": \"Age\",\n",
    "                                \"NRP\":\"O\",\n",
    "                                \"ZIP_CODE\":\"O\",\n",
    "                                \"EMAIL_ADDRESS\":\"Email\",\n",
    "                                \"DOMAIN_NAME\":\"URL\",\n",
    "                                \"IP_ADDRESS\":\"IPAddress\",\n",
    "                                \"IBAN_CODE\":\"InternationalBankingAccountNumber\",   \n",
    "                                \"US_DRIVER_LICENSE\":\"USDriversLicenseNumber\"\n",
    "                                }\n",
    "# List of entity names to focus the evaluator on (and ignore the rest) is defined with entities_to_keep parameter\n",
    "evaluator = Evaluator(model=model, entities_to_keep=[\"Person\", \"Address\"])\n",
    "dataset_ = Evaluator.align_entity_types(\n",
    "    deepcopy(dataset), entities_mapping=i2b2_entities_to_text_analytics\n",
    ")\n",
    "\n",
    "evaluation_results = evaluator.evaluate_all(dataset_)\n",
    "results = evaluator.calculate_score(evaluation_results)\n",
    "\n",
    "# update params tracking\n",
    "params = {\"dataset_name\": dataset_name, \"model_name\": model_name}\n",
    "params.update(model.to_log())\n",
    "experiment.log_parameters(params)\n",
    "experiment.log_dataset_hash(dataset)\n",
    "experiment.log_metrics(results.to_log())\n",
    "entities, confmatrix = results.to_confusion_matrix()\n",
    "experiment.log_confusion_matrix(matrix=confmatrix, labels=entities)\n",
    "\n",
    "# end experiment\n",
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "         Address  O\n",
      "Address        6  8\n",
      "O              0  5\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\")\n",
    "print(pd.DataFrame(confmatrix, columns=entities, index=entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision and recall\n",
      "              Entity           Precision              Recall   Number of samples\n",
      "             Address             100.00%              42.86%                  14\n",
      "        Organization                nan%               0.00%                   1\n",
      "                 PII             100.00%              40.00%                  15\n",
      "PII F measure: 43.61%\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision and recall\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('presidio')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "371968787ec79dd50357533864944a85029366968470cac36beb694745c2f7d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
